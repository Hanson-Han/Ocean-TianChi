{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as mtr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate, Reshape, Dropout, merge, Add\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
    "import warnings\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "import keras\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "PATH = '../input/oceantianchi/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_feather(PATH + 'train.feather')\n",
    "test = pd.read_feather(PATH + 'test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>渔船ID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>速度</th>\n",
       "      <th>方向</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, 渔船ID, x, y, 速度, 方向, time, type]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.isna().T.any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>渔船ID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>速度</th>\n",
       "      <th>方向</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [渔船ID, x, y, 速度, 方向, time]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.isna().T.any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>speed</th>\n",
       "      <th>ori</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6.152038e+06</td>\n",
       "      <td>5.124873e+06</td>\n",
       "      <td>2.59</td>\n",
       "      <td>102</td>\n",
       "      <td>1110 11:58:19</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6.151230e+06</td>\n",
       "      <td>5.125218e+06</td>\n",
       "      <td>2.70</td>\n",
       "      <td>113</td>\n",
       "      <td>1110 11:48:19</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6.150421e+06</td>\n",
       "      <td>5.125563e+06</td>\n",
       "      <td>2.70</td>\n",
       "      <td>116</td>\n",
       "      <td>1110 11:38:19</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6.149612e+06</td>\n",
       "      <td>5.125907e+06</td>\n",
       "      <td>3.29</td>\n",
       "      <td>95</td>\n",
       "      <td>1110 11:28:19</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6.148803e+06</td>\n",
       "      <td>5.126252e+06</td>\n",
       "      <td>3.18</td>\n",
       "      <td>108</td>\n",
       "      <td>1110 11:18:19</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id             x             y  speed  ori           time type\n",
       "0   0  6.152038e+06  5.124873e+06   2.59  102  1110 11:58:19   拖网\n",
       "1   0  6.151230e+06  5.125218e+06   2.70  113  1110 11:48:19   拖网\n",
       "2   0  6.150421e+06  5.125563e+06   2.70  116  1110 11:38:19   拖网\n",
       "3   0  6.149612e+06  5.125907e+06   3.29   95  1110 11:28:19   拖网\n",
       "4   0  6.148803e+06  5.126252e+06   3.18  108  1110 11:18:19   拖网"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "train.columns = ['id', 'x', 'y', 'speed', 'ori', 'time', 'type']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>speed</th>\n",
       "      <th>ori</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000</td>\n",
       "      <td>7.118845e+06</td>\n",
       "      <td>5.918277e+06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1103 11:54:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000</td>\n",
       "      <td>7.118940e+06</td>\n",
       "      <td>5.918285e+06</td>\n",
       "      <td>0.32</td>\n",
       "      <td>346</td>\n",
       "      <td>1103 11:44:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000</td>\n",
       "      <td>7.118948e+06</td>\n",
       "      <td>5.918174e+06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1103 11:34:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7000</td>\n",
       "      <td>7.118948e+06</td>\n",
       "      <td>5.918174e+06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>71</td>\n",
       "      <td>1103 11:14:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000</td>\n",
       "      <td>7.118948e+06</td>\n",
       "      <td>5.918174e+06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>30</td>\n",
       "      <td>1103 11:04:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id             x             y  speed  ori           time\n",
       "0  7000  7.118845e+06  5.918277e+06   0.11    0  1103 11:54:32\n",
       "1  7000  7.118940e+06  5.918285e+06   0.32  346  1103 11:44:32\n",
       "2  7000  7.118948e+06  5.918174e+06   0.11    0  1103 11:34:43\n",
       "3  7000  7.118948e+06  5.918174e+06   0.11   71  1103 11:14:30\n",
       "4  7000  7.118948e+06  5.918174e+06   0.11   30  1103 11:04:46"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns = ['id', 'x', 'y', 'speed', 'ori', 'time']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['拖网', '围网', '刺网'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>speed</th>\n",
       "      <th>ori</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6.152038e+06</td>\n",
       "      <td>5.124873e+06</td>\n",
       "      <td>2.59</td>\n",
       "      <td>102</td>\n",
       "      <td>1110 11:58:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6.151230e+06</td>\n",
       "      <td>5.125218e+06</td>\n",
       "      <td>2.70</td>\n",
       "      <td>113</td>\n",
       "      <td>1110 11:48:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6.150421e+06</td>\n",
       "      <td>5.125563e+06</td>\n",
       "      <td>2.70</td>\n",
       "      <td>116</td>\n",
       "      <td>1110 11:38:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6.149612e+06</td>\n",
       "      <td>5.125907e+06</td>\n",
       "      <td>3.29</td>\n",
       "      <td>95</td>\n",
       "      <td>1110 11:28:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6.148803e+06</td>\n",
       "      <td>5.126252e+06</td>\n",
       "      <td>3.18</td>\n",
       "      <td>108</td>\n",
       "      <td>1110 11:18:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699633</th>\n",
       "      <td>999</td>\n",
       "      <td>6.138413e+06</td>\n",
       "      <td>5.162715e+06</td>\n",
       "      <td>0.32</td>\n",
       "      <td>40</td>\n",
       "      <td>1031 13:09:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699634</th>\n",
       "      <td>999</td>\n",
       "      <td>6.138412e+06</td>\n",
       "      <td>5.162606e+06</td>\n",
       "      <td>0.22</td>\n",
       "      <td>275</td>\n",
       "      <td>1031 12:48:58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699635</th>\n",
       "      <td>999</td>\n",
       "      <td>6.138413e+06</td>\n",
       "      <td>5.162715e+06</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>1031 12:28:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699636</th>\n",
       "      <td>999</td>\n",
       "      <td>6.138413e+06</td>\n",
       "      <td>5.162715e+06</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>1031 12:18:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699637</th>\n",
       "      <td>999</td>\n",
       "      <td>6.138413e+06</td>\n",
       "      <td>5.162715e+06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>294</td>\n",
       "      <td>1031 12:07:59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2699638 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id             x             y  speed  ori           time  type\n",
       "0          0  6.152038e+06  5.124873e+06   2.59  102  1110 11:58:19     1\n",
       "1          0  6.151230e+06  5.125218e+06   2.70  113  1110 11:48:19     1\n",
       "2          0  6.150421e+06  5.125563e+06   2.70  116  1110 11:38:19     1\n",
       "3          0  6.149612e+06  5.125907e+06   3.29   95  1110 11:28:19     1\n",
       "4          0  6.148803e+06  5.126252e+06   3.18  108  1110 11:18:19     1\n",
       "...      ...           ...           ...    ...  ...            ...   ...\n",
       "2699633  999  6.138413e+06  5.162715e+06   0.32   40  1031 13:09:00     1\n",
       "2699634  999  6.138412e+06  5.162606e+06   0.22  275  1031 12:48:58     1\n",
       "2699635  999  6.138413e+06  5.162715e+06   0.32    0  1031 12:28:01     1\n",
       "2699636  999  6.138413e+06  5.162715e+06   0.32    0  1031 12:18:00     1\n",
       "2699637  999  6.138413e+06  5.162715e+06   0.11  294  1031 12:07:59     1\n",
       "\n",
       "[2699638 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_dict = {'围网':0, '拖网':1, '刺网':2}\n",
    "type_dict_inverse = {0:'围网', 1:'拖网', 2:'刺网'}\n",
    "\n",
    "train.type = train.type.map(type_dict)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(df, test=False):\n",
    "    df['speed'] = df['speed']\n",
    "    df['ori'] = df['ori'] / 180.0 * np.pi\n",
    "    df['speed_sin'] = df['speed'] * np.sin(df['ori'])\n",
    "    df['speed_cos'] = df['speed'] * np.cos(df['ori'])\n",
    "    \n",
    "    if test:\n",
    "        df = df.groupby(['id']).agg({'x': ['std', 'min', 'max', 'mean'], \n",
    "                                     'y': ['std', 'min', 'max', 'mean'], \n",
    "                                     'speed_sin': ['std', 'min', 'max', 'mean'], \n",
    "                                     'speed_cos': ['std', 'min', 'max', 'mean'], \n",
    "                                     'speed': ['std', 'min', 'max', 'mean'], \n",
    "                                     'ori': ['std', 'min', 'max', 'mean']}).reset_index()\n",
    "\n",
    "        df.columns = ['id', \n",
    "                      'x_std', 'x_min', 'x_max', 'x_mean',\n",
    "                      'y_std', 'y_min', 'y_max', 'y_mean', \n",
    "                      'speed_sin_std', 'speed_sin_min', 'speed_sin_max', 'speed_sin_mean', \n",
    "                      'speed_cos_std', 'speed_cos_min', 'speed_cos_max', 'speed_cos_mean',\n",
    "                      'speed_std', 'speed_min', 'speed_max', 'speed_mean', \n",
    "                      'ori_std', 'ori_min', 'ori_max', 'ori_mean']\n",
    "        \n",
    "    else:\n",
    "        df = df.groupby(['id', 'type']).agg({'x': ['std', 'min', 'max', 'mean'], \n",
    "                                             'y': ['std', 'min', 'max', 'mean'], \n",
    "                                             'speed_sin': ['std', 'min', 'max', 'mean'], \n",
    "                                             'speed_cos': ['std', 'min', 'max', 'mean'],\n",
    "                                             'speed': ['std', 'min', 'max', 'mean'], \n",
    "                                             'ori': ['std', 'min', 'max', 'mean']}).reset_index()\n",
    "        df.columns = ['id', 'type', \n",
    "                      'x_std', 'x_min', 'x_max', 'x_mean',\n",
    "                      'y_std', 'y_min', 'y_max', 'y_mean', \n",
    "                      'speed_sin_std', 'speed_sin_min', 'speed_sin_max', 'speed_sin_mean', \n",
    "                      'speed_cos_std', 'speed_cos_min', 'speed_cos_max', 'speed_cos_mean',\n",
    "                      'speed_std', 'speed_min', 'speed_max', 'speed_mean', \n",
    "                      'ori_std', 'ori_min', 'ori_max', 'ori_mean']\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = feature_engineer(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4c8bdf9e10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAElpJREFUeJzt3X+QXWV9x/H3V8IPJZYEo1sGogljphWkCuwgVafdgAMBWkOnMhOH1mDTydhiR6dOK5RpsSpTmJbiQNVOKozBMgSK2lDEsSlkx7FOQKJC+FFMgIzGMKSaEF1/0IZ++8d9Vi/r7t57s/ee3fC8XzN39pznPOee73lysp97zrn3bmQmkqT6vGS2C5AkzQ4DQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklSpebNdwHQWLVqUS5YsOej1f/SjH3H00Uf3r6A+sa7eWFdvrKs3L8a6tm7d+r3MfGXHjpk5Zx+nn356zsTmzZtntP6gWFdvrKs31tWbF2NdwAPZxe9YLwFJUqUMAEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKl5vRXQUhz2bbv7ueSy77Q+HZ3Xn1B49vUi5NnAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqVNcBEBGHRcQ3IuKuMr80Iu6LiO0RcVtEHFHajyzzO8ryJW3PcXlpfzwizu33zkiSutfLGcD7gMfa5q8BrsvMZcA+YE1pXwPsy8zXAteVfkTEScAq4GRgBfCJiDhsZuVLkg5WVwEQEScAFwCfKvMBnAXcUbqsBy4s0yvLPGX52aX/SmBDZj6XmU8BO4Az+rETkqTedXsG8DHgz4H/K/OvAJ7NzANlfhdwfJk+HvgOQFm+v/T/Wfsk60iSGtbxD8JExG8BezJza0SMjDdP0jU7LJtunfbtrQXWAgwNDTE6OtqpxCmNjY3NaP1Bsa7ezNW6hl4KHzjlQOeOfdZpLObqeFlXb5qoq5u/CPYW4O0RcT5wFPBLtM4IFkTEvPIq/wRgd+m/C1gM7IqIecAxwN629nHt6/xMZq4D1gEMDw/nyMjIQexWy+joKDNZf1Csqzdzta4bbtnItdua/6N6Oy8emXb5XB0v6+pNE3V1vASUmZdn5gmZuYTWTdx7M/NiYDPwjtJtNbCxTN9Z5inL783MLO2ryruElgLLgPv7tieSpJ7M5OXLB4ENEfFR4BvAjaX9RuAzEbGD1iv/VQCZ+UhE3A48ChwALs3M52ewfUnSDPQUAJk5CoyW6SeZ5F08mflT4KIp1r8KuKrXIiVJ/ecngSWpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASapUxwCIiKMi4v6IeDAiHomIvy7tSyPivojYHhG3RcQRpf3IMr+jLF/S9lyXl/bHI+LcQe2UJKmzbs4AngPOysw3AG8EVkTEmcA1wHWZuQzYB6wp/dcA+zLztcB1pR8RcRKwCjgZWAF8IiIO6+fOSJK61zEAsmWszB5eHgmcBdxR2tcDF5bplWWesvzsiIjSviEzn8vMp4AdwBl92QtJUs8iMzt3ar1S3wq8Fvg48LfAlvIqn4hYDHwxM18fEQ8DKzJzV1n2BPAm4ENlnX8u7TeWde6YsK21wFqAoaGh0zds2HDQOzc2Nsb8+fMPev1Bsa7ezNW69uzdzzM/aX67pxx/zLTL5+p4WVdvZlLX8uXLt2bmcKd+87p5ssx8HnhjRCwAPg+8brJu5WdMsWyq9onbWgesAxgeHs6RkZFuSpzU6OgoM1l/UKyrN3O1rhtu2ci127r6L9RXOy8emXb5XB0v6+pNE3X19C6gzHwWGAXOBBZExPjRfwKwu0zvAhYDlOXHAHvb2ydZR5LUsG7eBfTK8sqfiHgp8DbgMWAz8I7SbTWwsUzfWeYpy+/N1nWmO4FV5V1CS4FlwP392hFJUm+6OX89Dlhf7gO8BLg9M++KiEeBDRHxUeAbwI2l/43AZyJiB61X/qsAMvORiLgdeBQ4AFxaLi1JkmZBxwDIzIeAUydpf5JJ3sWTmT8FLpriua4Cruq9TElSv/lJYEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUqY4BEBGLI2JzRDwWEY9ExPtK+7ERsSkitpefC0t7RMT1EbEjIh6KiNPanmt16b89IlYPbrckSZ10cwZwAPhAZr4OOBO4NCJOAi4D7snMZcA9ZR7gPGBZeawFPgmtwACuBN4EnAFcOR4akqTmdQyAzHw6M79epn8IPAYcD6wE1pdu64ELy/RK4OZs2QIsiIjjgHOBTZm5NzP3AZuAFX3dG0lS13q6BxARS4BTgfuAocx8GlohAbyqdDse+E7bartK21TtkqRZMK/bjhExH/gs8P7M/EFETNl1kracpn3idtbSunTE0NAQo6Oj3Zb4C8bGxma0/qBYV2/mal1DL4UPnHKg8e12Gou5Ol7W1Zsm6uoqACLicFq//G/JzM+V5mci4rjMfLpc4tlT2ncBi9tWPwHYXdpHJrSPTtxWZq4D1gEMDw/nyMjIxC5dGx0dZSbrD4p19Wau1nXDLRu5dlvXr6H6ZufFI9Mun6vjZV29aaKubt4FFMCNwGOZ+fdti+4Ext/JsxrY2Nb+rvJuoDOB/eUS0ZeAcyJiYbn5e05pkyTNgm5evrwF+H1gW0R8s7T9BXA1cHtErAG+DVxUlt0NnA/sAH4MvBsgM/dGxEeAr5V+H87MvX3ZC0lSzzoGQGZ+hcmv3wOcPUn/BC6d4rluAm7qpUBJ0mD4SWBJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlSBoAkVcoAkKRKNf/XLBq07bv7ueSyLzS+3Z1XX9D4NiWpV54BSFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlOgZARNwUEXsi4uG2tmMjYlNEbC8/F5b2iIjrI2JHRDwUEae1rbO69N8eEasHszuSpG51cwbwaWDFhLbLgHsycxlwT5kHOA9YVh5rgU9CKzCAK4E3AWcAV46HhiRpdszr1CEzvxwRSyY0rwRGyvR6YBT4YGm/OTMT2BIRCyLiuNJ3U2buBYiITbRC5dYZ74EkDciSy74wa9v+9IqjB76NaP2u7tCpFQB3Zebry/yzmbmgbfm+zFwYEXcBV2fmV0r7PbSCYQQ4KjM/Wtr/EvhJZv7dJNtaS+vsgaGhodM3bNhw0Du3Z+9+nvnJQa9+0E45/phpl4+NjTF//vyGqumedfXG46s3h2Jd2767v+Fqfm7pMYcd9HgtX758a2YOd+rX8QygRzFJW07T/ouNmeuAdQDDw8M5MjJy0MXccMtGrt3W713sbOfFI9MuHx0dZSb7NSjW1RuPr94cinVdMstnAIMer4N9F9Az5dIO5eee0r4LWNzW7wRg9zTtkqRZcrABcCcw/k6e1cDGtvZ3lXcDnQnsz8yngS8B50TEwnLz95zSJkmaJR3PXyPiVlrX8BdFxC5a7+a5Grg9ItYA3wYuKt3vBs4HdgA/Bt4NkJl7I+IjwNdKvw+P3xCWJM2Obt4F9M4pFp09Sd8ELp3ieW4CbuqpOknSwPhJYEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUqcYDICJWRMTjEbEjIi5revuSpJZGAyAiDgM+DpwHnAS8MyJOarIGSVJL02cAZwA7MvPJzPwfYAOwsuEaJEk0HwDHA99pm99V2iRJDZvX8PZikrZ8QYeItcDaMjsWEY/PYHuLgO/NYP2DEtd07DIrdXXBunrj8dUb6+rB8mtmVNdruunUdADsAha3zZ8A7G7vkJnrgHX92FhEPJCZw/14rn6yrt5YV2+sqzc119X0JaCvAcsiYmlEHAGsAu5suAZJEg2fAWTmgYh4L/Al4DDgpsx8pMkaJEktTV8CIjPvBu5uaHN9uZQ0ANbVG+vqjXX1ptq6IjM795Ikvej4VRCSVKlDMgA6fZ1ERBwZEbeV5fdFxJK2ZZeX9scj4tyG6/rTiHg0Ih6KiHsi4jVty56PiG+WR19vjHdR1yUR8d9t2//DtmWrI2J7eaxuuK7r2mr6VkQ827ZskON1U0TsiYiHp1geEXF9qfuhiDitbdkgx6tTXReXeh6KiK9GxBvalu2MiG1lvB5ouK6RiNjf9u/1V23LBvbVMF3U9WdtNT1cjqljy7JBjtfiiNgcEY9FxCMR8b5J+jRzjGXmIfWgdfP4CeBE4AjgQeCkCX3+GPjHMr0KuK1Mn1T6HwksLc9zWIN1LQdeVqb/aLyuMj82i+N1CfAPk6x7LPBk+bmwTC9sqq4J/f+E1psGBjpe5bl/AzgNeHiK5ecDX6T1uZYzgfsGPV5d1vXm8e3R+rqV+9qW7QQWzdJ4jQB3zfQY6HddE/r+NnBvQ+N1HHBamX458K1J/k82cowdimcA3XydxEpgfZm+Azg7IqK0b8jM5zLzKWBHeb5G6srMzZn54zK7hdbnIAZtJl+/cS6wKTP3ZuY+YBOwYpbqeidwa5+2Pa3M/DKwd5ouK4Gbs2ULsCAijmOw49Wxrsz8atkuNHd8dTNeUxnoV8P0WFeTx9fTmfn1Mv1D4DF+8RsRGjnGDsUA6ObrJH7WJzMPAPuBV3S57iDrareGVsKPOyoiHoiILRFxYZ9q6qWu3y2nmndExPiH9ebEeJVLZUuBe9uaBzVe3Ziq9rn0VScTj68E/j0itkbr0/ZN+/WIeDAivhgRJ5e2OTFeEfEyWr9EP9vW3Mh4Revy9KnAfRMWNXKMNf420D7o+HUS0/TpZt2D1fVzR8TvAcPAb7Y1vzozd0fEicC9EbEtM59oqK5/A27NzOci4j20zp7O6nLdQdY1bhVwR2Y+39Y2qPHqxmwcX12LiOW0AuCtbc1vKeP1KmBTRPxXeYXchK8Dr8nMsYg4H/hXYBlzZLxoXf75z8xsP1sY+HhFxHxaofP+zPzBxMWTrNL3Y+xQPAPo+HUS7X0iYh5wDK1TwW7WHWRdRMTbgCuAt2fmc+Ptmbm7/HwSGKX1qqCRujLz+221/BNwerfrDrKuNquYcHo+wPHqxlS1D3K8uhIRvwZ8CliZmd8fb28brz3A5+nfpc+OMvMHmTlWpu8GDo+IRcyB8SqmO74GMl4RcTitX/63ZObnJunSzDE2iJscg3zQOmt5ktYlgfEbRydP6HMpL7wJfHuZPpkX3gR+kv7dBO6mrlNp3fRaNqF9IXBkmV4EbKdPN8O6rOu4tunfAbbkz284PVXqW1imj22qrtLvV2jdkIsmxqttG0uY+qbmBbzwBt39gx6vLut6Na37Wm+e0H408PK26a8CKxqs65fH//1o/SL9dhm7ro6BQdVVlo+/ODy6qfEq+34z8LFp+jRyjPVtoJt80LpD/i1av0yvKG0fpvWqGuAo4F/Kf4b7gRPb1r2irPc4cF7Ddf0H8AzwzfK4s7S/GdhW/gNsA9Y0XNffAI+U7W8GfrVt3T8o47gDeHeTdZX5DwFXT1hv0ON1K/A08L+0XnGtAd4DvKcsD1p/2OiJsv3hhsarU12fAva1HV8PlPYTy1g9WP6dr2i4rve2HV9baAuoyY6BpuoqfS6h9caQ9vUGPV5vpXXZ5qG2f6vzZ+MY85PAklSpQ/EegCSpDwwASaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIq9f9r2k9jRcyn3wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = train.type\n",
    "target.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important = ['x_std', 'x_min', 'x_max', 'x_mean', \n",
    "            'y_std', 'y_min', 'y_max', 'y_mean', \n",
    "            'speed_sin_std', 'speed_sin_max', 'speed_sin_mean', \n",
    "            'speed_cos_std', 'speed_cos_max', 'speed_cos_mean',\n",
    "            'speed_std', 'speed_max', 'speed_mean', \n",
    "            'ori_std', 'ori_max', 'ori_mean']\n",
    "\n",
    "num = ['id', \n",
    "       'x_std', 'x_min', 'x_max', 'x_mean', \n",
    "       'y_std', 'y_min', 'y_max', 'y_mean', \n",
    "       'speed_sin_std', 'speed_sin_min', 'speed_sin_max', 'speed_sin_mean', \n",
    "       'speed_cos_std', 'speed_cos_min', 'speed_cos_max', 'speed_cos_mean',\n",
    "       'speed_std', 'speed_min', 'speed_max', 'speed_mean', \n",
    "       'ori_std', 'ori_min', 'ori_max', 'ori_mean']\n",
    "\n",
    "features = [i for i in num if i in important]\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_std</th>\n",
       "      <th>x_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>x_mean</th>\n",
       "      <th>y_std</th>\n",
       "      <th>y_min</th>\n",
       "      <th>y_max</th>\n",
       "      <th>y_mean</th>\n",
       "      <th>speed_sin_std</th>\n",
       "      <th>speed_sin_max</th>\n",
       "      <th>speed_sin_mean</th>\n",
       "      <th>speed_cos_std</th>\n",
       "      <th>speed_cos_max</th>\n",
       "      <th>speed_cos_mean</th>\n",
       "      <th>speed_std</th>\n",
       "      <th>speed_max</th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>ori_std</th>\n",
       "      <th>ori_max</th>\n",
       "      <th>ori_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.561751</td>\n",
       "      <td>-0.481411</td>\n",
       "      <td>-0.583659</td>\n",
       "      <td>-0.589869</td>\n",
       "      <td>-0.733104</td>\n",
       "      <td>-0.451055</td>\n",
       "      <td>-0.635067</td>\n",
       "      <td>-0.557333</td>\n",
       "      <td>-0.465947</td>\n",
       "      <td>0.575714</td>\n",
       "      <td>0.489416</td>\n",
       "      <td>-1.374942</td>\n",
       "      <td>-1.135842</td>\n",
       "      <td>-0.132880</td>\n",
       "      <td>-0.493257</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-1.105644</td>\n",
       "      <td>-2.971593</td>\n",
       "      <td>-3.894416</td>\n",
       "      <td>-2.174746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.074971</td>\n",
       "      <td>-0.737770</td>\n",
       "      <td>-0.764905</td>\n",
       "      <td>-0.693781</td>\n",
       "      <td>0.547405</td>\n",
       "      <td>-0.774836</td>\n",
       "      <td>-0.704157</td>\n",
       "      <td>-0.702666</td>\n",
       "      <td>0.153581</td>\n",
       "      <td>-0.407276</td>\n",
       "      <td>-0.243683</td>\n",
       "      <td>0.257997</td>\n",
       "      <td>-0.695451</td>\n",
       "      <td>-0.728231</td>\n",
       "      <td>0.581405</td>\n",
       "      <td>0.092406</td>\n",
       "      <td>-0.148014</td>\n",
       "      <td>-0.397695</td>\n",
       "      <td>-0.166976</td>\n",
       "      <td>-1.178604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.766067</td>\n",
       "      <td>-0.242729</td>\n",
       "      <td>-0.469796</td>\n",
       "      <td>-0.352696</td>\n",
       "      <td>-0.774045</td>\n",
       "      <td>-0.179835</td>\n",
       "      <td>-0.392333</td>\n",
       "      <td>-0.305347</td>\n",
       "      <td>0.991019</td>\n",
       "      <td>8.387629</td>\n",
       "      <td>0.543785</td>\n",
       "      <td>-0.001446</td>\n",
       "      <td>3.580308</td>\n",
       "      <td>0.361676</td>\n",
       "      <td>1.569120</td>\n",
       "      <td>6.075185</td>\n",
       "      <td>-0.870736</td>\n",
       "      <td>0.762649</td>\n",
       "      <td>0.265191</td>\n",
       "      <td>0.120273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.034344</td>\n",
       "      <td>-3.792945</td>\n",
       "      <td>-3.742437</td>\n",
       "      <td>-3.869174</td>\n",
       "      <td>-0.202379</td>\n",
       "      <td>-2.612089</td>\n",
       "      <td>-2.649613</td>\n",
       "      <td>-2.666767</td>\n",
       "      <td>0.443121</td>\n",
       "      <td>0.488293</td>\n",
       "      <td>0.156091</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.645021</td>\n",
       "      <td>0.069020</td>\n",
       "      <td>0.695528</td>\n",
       "      <td>0.035555</td>\n",
       "      <td>-0.245478</td>\n",
       "      <td>0.713557</td>\n",
       "      <td>0.121135</td>\n",
       "      <td>0.077329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.521887</td>\n",
       "      <td>2.983762</td>\n",
       "      <td>2.774408</td>\n",
       "      <td>2.922148</td>\n",
       "      <td>-0.179424</td>\n",
       "      <td>3.378767</td>\n",
       "      <td>3.243342</td>\n",
       "      <td>3.374298</td>\n",
       "      <td>0.131911</td>\n",
       "      <td>0.505638</td>\n",
       "      <td>-0.144988</td>\n",
       "      <td>0.268948</td>\n",
       "      <td>0.621621</td>\n",
       "      <td>0.029078</td>\n",
       "      <td>0.664260</td>\n",
       "      <td>0.035555</td>\n",
       "      <td>-0.287669</td>\n",
       "      <td>0.690527</td>\n",
       "      <td>0.247184</td>\n",
       "      <td>0.423932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>0.954782</td>\n",
       "      <td>-0.051338</td>\n",
       "      <td>0.078406</td>\n",
       "      <td>0.048052</td>\n",
       "      <td>0.885207</td>\n",
       "      <td>-0.350640</td>\n",
       "      <td>-0.170606</td>\n",
       "      <td>-0.248711</td>\n",
       "      <td>0.442434</td>\n",
       "      <td>0.591762</td>\n",
       "      <td>1.213694</td>\n",
       "      <td>1.455428</td>\n",
       "      <td>-0.221410</td>\n",
       "      <td>-0.599728</td>\n",
       "      <td>0.964440</td>\n",
       "      <td>0.035555</td>\n",
       "      <td>0.906308</td>\n",
       "      <td>0.822867</td>\n",
       "      <td>0.265191</td>\n",
       "      <td>0.588547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>-0.226792</td>\n",
       "      <td>0.686989</td>\n",
       "      <td>0.667973</td>\n",
       "      <td>0.692415</td>\n",
       "      <td>-0.023549</td>\n",
       "      <td>0.763154</td>\n",
       "      <td>0.769158</td>\n",
       "      <td>0.760091</td>\n",
       "      <td>0.107118</td>\n",
       "      <td>0.186597</td>\n",
       "      <td>0.545167</td>\n",
       "      <td>0.806734</td>\n",
       "      <td>0.074428</td>\n",
       "      <td>-0.189717</td>\n",
       "      <td>-0.463305</td>\n",
       "      <td>-0.149957</td>\n",
       "      <td>0.864612</td>\n",
       "      <td>0.122281</td>\n",
       "      <td>0.229177</td>\n",
       "      <td>0.702050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>-0.007499</td>\n",
       "      <td>-3.792534</td>\n",
       "      <td>-3.743690</td>\n",
       "      <td>-3.865215</td>\n",
       "      <td>-0.181948</td>\n",
       "      <td>-2.611080</td>\n",
       "      <td>-2.649613</td>\n",
       "      <td>-2.669614</td>\n",
       "      <td>0.560050</td>\n",
       "      <td>0.487543</td>\n",
       "      <td>0.117786</td>\n",
       "      <td>-0.245987</td>\n",
       "      <td>0.290478</td>\n",
       "      <td>0.155278</td>\n",
       "      <td>0.637974</td>\n",
       "      <td>0.035555</td>\n",
       "      <td>-0.224255</td>\n",
       "      <td>0.579324</td>\n",
       "      <td>0.157149</td>\n",
       "      <td>0.395363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>-0.416964</td>\n",
       "      <td>0.436643</td>\n",
       "      <td>0.277411</td>\n",
       "      <td>0.356727</td>\n",
       "      <td>0.460642</td>\n",
       "      <td>0.412054</td>\n",
       "      <td>0.493816</td>\n",
       "      <td>0.499432</td>\n",
       "      <td>-0.274385</td>\n",
       "      <td>0.458726</td>\n",
       "      <td>0.096619</td>\n",
       "      <td>0.523549</td>\n",
       "      <td>0.579499</td>\n",
       "      <td>-0.737121</td>\n",
       "      <td>0.207946</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.102791</td>\n",
       "      <td>0.296266</td>\n",
       "      <td>0.265191</td>\n",
       "      <td>0.393043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>-0.543992</td>\n",
       "      <td>-0.153814</td>\n",
       "      <td>-0.260999</td>\n",
       "      <td>-0.157408</td>\n",
       "      <td>0.267429</td>\n",
       "      <td>-0.422811</td>\n",
       "      <td>-0.253074</td>\n",
       "      <td>-0.187750</td>\n",
       "      <td>-0.859283</td>\n",
       "      <td>0.191737</td>\n",
       "      <td>0.386051</td>\n",
       "      <td>0.524158</td>\n",
       "      <td>0.637523</td>\n",
       "      <td>1.326763</td>\n",
       "      <td>0.626070</td>\n",
       "      <td>0.035555</td>\n",
       "      <td>-0.610770</td>\n",
       "      <td>0.368789</td>\n",
       "      <td>0.265191</td>\n",
       "      <td>-0.648687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x_std     x_min     x_max    x_mean     y_std     y_min     y_max  \\\n",
       "0    -0.561751 -0.481411 -0.583659 -0.589869 -0.733104 -0.451055 -0.635067   \n",
       "1    -0.074971 -0.737770 -0.764905 -0.693781  0.547405 -0.774836 -0.704157   \n",
       "2    -0.766067 -0.242729 -0.469796 -0.352696 -0.774045 -0.179835 -0.392333   \n",
       "3    -0.034344 -3.792945 -3.742437 -3.869174 -0.202379 -2.612089 -2.649613   \n",
       "4    -0.521887  2.983762  2.774408  2.922148 -0.179424  3.378767  3.243342   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6995  0.954782 -0.051338  0.078406  0.048052  0.885207 -0.350640 -0.170606   \n",
       "6996 -0.226792  0.686989  0.667973  0.692415 -0.023549  0.763154  0.769158   \n",
       "6997 -0.007499 -3.792534 -3.743690 -3.865215 -0.181948 -2.611080 -2.649613   \n",
       "6998 -0.416964  0.436643  0.277411  0.356727  0.460642  0.412054  0.493816   \n",
       "6999 -0.543992 -0.153814 -0.260999 -0.157408  0.267429 -0.422811 -0.253074   \n",
       "\n",
       "        y_mean  speed_sin_std  speed_sin_max  speed_sin_mean  speed_cos_std  \\\n",
       "0    -0.557333      -0.465947       0.575714        0.489416      -1.374942   \n",
       "1    -0.702666       0.153581      -0.407276       -0.243683       0.257997   \n",
       "2    -0.305347       0.991019       8.387629        0.543785      -0.001446   \n",
       "3    -2.666767       0.443121       0.488293        0.156091      -0.011480   \n",
       "4     3.374298       0.131911       0.505638       -0.144988       0.268948   \n",
       "...        ...            ...            ...             ...            ...   \n",
       "6995 -0.248711       0.442434       0.591762        1.213694       1.455428   \n",
       "6996  0.760091       0.107118       0.186597        0.545167       0.806734   \n",
       "6997 -2.669614       0.560050       0.487543        0.117786      -0.245987   \n",
       "6998  0.499432      -0.274385       0.458726        0.096619       0.523549   \n",
       "6999 -0.187750      -0.859283       0.191737        0.386051       0.524158   \n",
       "\n",
       "      speed_cos_max  speed_cos_mean  speed_std  speed_max  speed_mean  \\\n",
       "0         -1.135842       -0.132880  -0.493257  -0.069170   -1.105644   \n",
       "1         -0.695451       -0.728231   0.581405   0.092406   -0.148014   \n",
       "2          3.580308        0.361676   1.569120   6.075185   -0.870736   \n",
       "3          0.645021        0.069020   0.695528   0.035555   -0.245478   \n",
       "4          0.621621        0.029078   0.664260   0.035555   -0.287669   \n",
       "...             ...             ...        ...        ...         ...   \n",
       "6995      -0.221410       -0.599728   0.964440   0.035555    0.906308   \n",
       "6996       0.074428       -0.189717  -0.463305  -0.149957    0.864612   \n",
       "6997       0.290478        0.155278   0.637974   0.035555   -0.224255   \n",
       "6998       0.579499       -0.737121   0.207946   0.004138    0.102791   \n",
       "6999       0.637523        1.326763   0.626070   0.035555   -0.610770   \n",
       "\n",
       "       ori_std   ori_max  ori_mean  \n",
       "0    -2.971593 -3.894416 -2.174746  \n",
       "1    -0.397695 -0.166976 -1.178604  \n",
       "2     0.762649  0.265191  0.120273  \n",
       "3     0.713557  0.121135  0.077329  \n",
       "4     0.690527  0.247184  0.423932  \n",
       "...        ...       ...       ...  \n",
       "6995  0.822867  0.265191  0.588547  \n",
       "6996  0.122281  0.229177  0.702050  \n",
       "6997  0.579324  0.157149  0.395363  \n",
       "6998  0.296266  0.265191  0.393043  \n",
       "6999  0.368789  0.265191 -0.648687  \n",
       "\n",
       "[7000 rows x 20 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train[important] = scaler.fit_transform(train[important])\n",
    "train[important]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cm_plot(original_label, predict_label, pic=None):\n",
    "    cm = confusion_matrix(original_label, predict_label)   # 由原标签和预测标签生成混淆矩阵\n",
    "    plt.figure()\n",
    "    plt.matshow(cm, cmap=plt.cm.Blues)     # 画混淆矩阵，配色风格使用cm.Blues\n",
    "    plt.colorbar()    # 颜色标签\n",
    "    for x in range(len(cm)):\n",
    "        for y in range(len(cm)):\n",
    "            plt.annotate(cm[x, y], xy=(x, y), horizontalalignment='center', verticalalignment='center')\n",
    "    plt.xlabel('True label')  # 坐标轴标签\n",
    "    plt.ylabel('Predicted label')  # 坐标轴标签\n",
    "    plt.title('confusion matrix')\n",
    "    if pic is not None:\n",
    "        plt.savefig(str(pic) + '.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(y_true, y_pred):\n",
    "    C=confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    TP_0 = C[0][0]\n",
    "    FN_0 = C[0][1] + C[0][2]\n",
    "    FP_0 = C[1][0] + C[2][0]\n",
    "    TN_0 = sum(sum(C)) - TP_0 - FN_0 - FP_0\n",
    "    precision_0 = TP_0/(TP_0 + FP_0)\n",
    "    recall_0 = TP_0/(TP_0 + FN_0)\n",
    "    F1_0 = 2 * precision_0 * recall_0/(precision_0 + recall_0)\n",
    "    \n",
    "    TP_1 = C[1][1]\n",
    "    FN_1 = C[1][0] + C[1][2]\n",
    "    FP_1 = C[0][1] + C[2][1]\n",
    "    TN_1 = sum(sum(C)) - TP_1 - FN_1 - FP_1\n",
    "    precision_1 = TP_1/(TP_1 + FP_1)\n",
    "    recall_1 = TP_1/(TP_1 + FN_1)\n",
    "    F1_1 = 2 * precision_1 * recall_1/(precision_1 + recall_1)\n",
    "    \n",
    "    TP_2 = C[2][2]\n",
    "    FN_2 = C[2][0] + C[2][1]\n",
    "    FP_2 = C[0][2] + C[1][2]\n",
    "    TN_2 = sum(sum(C)) - TP_2 - FN_2 - FP_2\n",
    "    precision_2 = TP_2/(TP_2 + FP_2)\n",
    "    recall_2 = TP_2/(TP_2 + FN_2)\n",
    "    F1_2 = 2 * precision_2 * recall_2/(precision_2 + recall_2)\n",
    "    return F1_0, F1_1, F1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "target = to_categorical(target)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model():\n",
    "    init = keras.initializers.glorot_uniform(seed=1)\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dense(units=32, input_dim=len(important), kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(units=64, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=32, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(units=16, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(units=8, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(units=3, kernel_initializer=init, activation='softmax'))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric(Callback):\n",
    "    def __init__(self, model, callbacks, data):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.callbacks = callbacks\n",
    "        self.data = data\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_end(logs)\n",
    "\n",
    "    def on_epoch_end(self, batch, logs=None):\n",
    "        X_train, y_train = self.data[0][0], self.data[0][1]\n",
    "        y_pred3 = self.model.predict(X_train)\n",
    "        y_pred = np.zeros((len(y_pred3), ))\n",
    "        y_true = np.zeros((len(y_pred3), ))\n",
    "        for i in range(len(y_pred3)):\n",
    "            y_pred[i] = list(y_pred3[i]).index(max(y_pred3[i]))\n",
    "        for i in range(len(y_pred3)):\n",
    "            y_true[i] = list(y_train[i]).index(max(y_train[i]))\n",
    "        trn_s = f1_score(y_true, y_pred, average='macro')\n",
    "        logs['trn_score'] = trn_s\n",
    "        \n",
    "        X_val, y_val = self.data[1][0], self.data[1][1]\n",
    "        y_pred3 = self.model.predict(X_val)\n",
    "        y_pred = np.zeros((len(y_pred3), ))\n",
    "        y_true = np.zeros((len(y_pred3), ))\n",
    "        for i in range(len(y_pred3)):\n",
    "            y_pred[i] = list(y_pred3[i]).index(max(y_pred3[i]))\n",
    "        for i in range(len(y_pred3)):\n",
    "            y_true[i] = list(y_val[i]).index(max(y_val[i]))\n",
    "        val_s = f1_score(y_true, y_pred, average='macro')\n",
    "        logs['val_score'] = val_s\n",
    "        print('trn_score', trn_s, 'val_score', val_s)\n",
    "\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_epoch_end(batch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "Train on 5598 samples, validate on 1402 samples\n",
      "Epoch 1/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.6787 - accuracy: 0.7199 - val_loss: 0.6336 - val_accuracy: 0.7190\n",
      "trn_score 0.6956237879616752 val_score 0.6492038314954588\n",
      "Epoch 2/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.5951 - accuracy: 0.7510 - val_loss: 0.6014 - val_accuracy: 0.7475\n",
      "trn_score 0.7058945315153456 val_score 0.6794128172071936\n",
      "Epoch 3/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.5529 - accuracy: 0.7674 - val_loss: 0.5578 - val_accuracy: 0.7518\n",
      "trn_score 0.6922057435352951 val_score 0.6558652348316647\n",
      "Epoch 4/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.5319 - accuracy: 0.7690 - val_loss: 0.5671 - val_accuracy: 0.7461\n",
      "trn_score 0.7286320355938551 val_score 0.6873080803931927\n",
      "Epoch 5/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.5228 - accuracy: 0.7749 - val_loss: 0.5591 - val_accuracy: 0.7489\n",
      "trn_score 0.7130495750927901 val_score 0.6649791816422509\n",
      "Epoch 6/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.5100 - accuracy: 0.7772 - val_loss: 0.5375 - val_accuracy: 0.7511\n",
      "trn_score 0.7270782110301365 val_score 0.6842632548465133\n",
      "Epoch 7/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.5143 - accuracy: 0.7731 - val_loss: 0.5266 - val_accuracy: 0.7625\n",
      "trn_score 0.7282741125577585 val_score 0.686655381253625\n",
      "Epoch 8/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4993 - accuracy: 0.7726 - val_loss: 0.5312 - val_accuracy: 0.7611\n",
      "trn_score 0.7272745552354708 val_score 0.6801359656208833\n",
      "Epoch 9/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4934 - accuracy: 0.7840 - val_loss: 0.5327 - val_accuracy: 0.7454\n",
      "trn_score 0.7422361685221973 val_score 0.6840879819947178\n",
      "Epoch 10/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4876 - accuracy: 0.7844 - val_loss: 0.5336 - val_accuracy: 0.7568\n",
      "trn_score 0.6462626569392612 val_score 0.6000078114487318\n",
      "Epoch 11/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4847 - accuracy: 0.7815 - val_loss: 0.5143 - val_accuracy: 0.7660\n",
      "trn_score 0.6982402496556573 val_score 0.6420317307266205\n",
      "Epoch 12/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4739 - accuracy: 0.7862 - val_loss: 0.5104 - val_accuracy: 0.7646\n",
      "trn_score 0.7368643055665588 val_score 0.6833983199165109\n",
      "Epoch 13/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4788 - accuracy: 0.7840 - val_loss: 0.5026 - val_accuracy: 0.7746\n",
      "trn_score 0.7328343658592368 val_score 0.6915736589888803\n",
      "Epoch 14/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4730 - accuracy: 0.7885 - val_loss: 0.5237 - val_accuracy: 0.7632\n",
      "trn_score 0.7256524400828356 val_score 0.6735944071556487\n",
      "Epoch 15/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4656 - accuracy: 0.7887 - val_loss: 0.4985 - val_accuracy: 0.7789\n",
      "trn_score 0.7226708894801467 val_score 0.685787227292784\n",
      "Epoch 16/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4631 - accuracy: 0.7946 - val_loss: 0.5043 - val_accuracy: 0.7725\n",
      "trn_score 0.723440584905367 val_score 0.6776568133486051\n",
      "Epoch 17/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4588 - accuracy: 0.7965 - val_loss: 0.5110 - val_accuracy: 0.7732\n",
      "trn_score 0.7477925342611448 val_score 0.7032857336505844\n",
      "Epoch 18/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4625 - accuracy: 0.7872 - val_loss: 0.4992 - val_accuracy: 0.7603\n",
      "trn_score 0.7533828576447524 val_score 0.6949419772229465\n",
      "Epoch 19/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4531 - accuracy: 0.7956 - val_loss: 0.4954 - val_accuracy: 0.7789\n",
      "trn_score 0.7448912294781129 val_score 0.6888511700105903\n",
      "Epoch 20/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4540 - accuracy: 0.7969 - val_loss: 0.5162 - val_accuracy: 0.7732\n",
      "trn_score 0.7455518469326116 val_score 0.6844532540317355\n",
      "Epoch 21/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4504 - accuracy: 0.7883 - val_loss: 0.4860 - val_accuracy: 0.7846\n",
      "trn_score 0.7426537464136852 val_score 0.6955883915205949\n",
      "Epoch 22/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4450 - accuracy: 0.7967 - val_loss: 0.4937 - val_accuracy: 0.7739\n",
      "trn_score 0.6966218042455784 val_score 0.664470548545154\n",
      "Epoch 23/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4490 - accuracy: 0.7917 - val_loss: 0.4909 - val_accuracy: 0.7725\n",
      "trn_score 0.751742485332695 val_score 0.6980825482858003\n",
      "Epoch 24/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4402 - accuracy: 0.8044 - val_loss: 0.5097 - val_accuracy: 0.7796\n",
      "trn_score 0.7075118877250085 val_score 0.6637126344363745\n",
      "Epoch 25/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4381 - accuracy: 0.8026 - val_loss: 0.5089 - val_accuracy: 0.7668\n",
      "trn_score 0.7559483360212611 val_score 0.6889732229143971\n",
      "Epoch 26/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4395 - accuracy: 0.7960 - val_loss: 0.4988 - val_accuracy: 0.7653\n",
      "trn_score 0.7570240342841977 val_score 0.7002969521375636\n",
      "Epoch 27/100\n",
      "5598/5598 [==============================] - 6s 1ms/step - loss: 0.4418 - accuracy: 0.7978 - val_loss: 0.4838 - val_accuracy: 0.7668\n",
      "trn_score 0.7305055412586235 val_score 0.6624401049676839\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00027: early stopping\n",
      "\n",
      "F1_0_val is:0.71071953010279, F1_1_val is:0.850989522700815, F1_2_val is:0.5481481481481482, total score is : 0.7032857336505844\n",
      "\n",
      "fold: 1\n",
      "Train on 5600 samples, validate on 1400 samples\n",
      "Epoch 1/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.6904 - accuracy: 0.7016 - val_loss: 0.6074 - val_accuracy: 0.7307\n",
      "trn_score 0.6814913492286987 val_score 0.662939335932951\n",
      "Epoch 2/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.5982 - accuracy: 0.7414 - val_loss: 0.5801 - val_accuracy: 0.7579\n",
      "trn_score 0.6123387806208136 val_score 0.6102229527782596\n",
      "Epoch 3/100\n",
      "5600/5600 [==============================] - 6s 991us/step - loss: 0.5654 - accuracy: 0.7554 - val_loss: 0.5532 - val_accuracy: 0.7536\n",
      "trn_score 0.7040112130300328 val_score 0.6692168739720818\n",
      "Epoch 4/100\n",
      "5600/5600 [==============================] - 6s 991us/step - loss: 0.5479 - accuracy: 0.7609 - val_loss: 0.5396 - val_accuracy: 0.7629\n",
      "trn_score 0.7151067400071199 val_score 0.7024473965806872\n",
      "Epoch 5/100\n",
      "5600/5600 [==============================] - 6s 983us/step - loss: 0.5342 - accuracy: 0.7711 - val_loss: 0.5398 - val_accuracy: 0.7621\n",
      "trn_score 0.6633943445336364 val_score 0.6432567085488943\n",
      "Epoch 6/100\n",
      "5600/5600 [==============================] - 6s 987us/step - loss: 0.5228 - accuracy: 0.7675 - val_loss: 0.5301 - val_accuracy: 0.7700\n",
      "trn_score 0.713840270441807 val_score 0.6918223622412104\n",
      "Epoch 7/100\n",
      "5600/5600 [==============================] - 6s 994us/step - loss: 0.5202 - accuracy: 0.7675 - val_loss: 0.5291 - val_accuracy: 0.7671\n",
      "trn_score 0.6605031844874151 val_score 0.6404646337395002\n",
      "Epoch 8/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.5138 - accuracy: 0.7750 - val_loss: 0.5218 - val_accuracy: 0.7671\n",
      "trn_score 0.7319259105094176 val_score 0.7133577777625666\n",
      "Epoch 9/100\n",
      "5600/5600 [==============================] - 6s 992us/step - loss: 0.5059 - accuracy: 0.7704 - val_loss: 0.5248 - val_accuracy: 0.7700\n",
      "trn_score 0.7236910128920221 val_score 0.6956107569995854\n",
      "Epoch 10/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.5005 - accuracy: 0.7809 - val_loss: 0.5232 - val_accuracy: 0.7686\n",
      "trn_score 0.6458407642416079 val_score 0.6231559236060712\n",
      "Epoch 11/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.4973 - accuracy: 0.7766 - val_loss: 0.5184 - val_accuracy: 0.7700\n",
      "trn_score 0.6657499624910647 val_score 0.6491126621082909\n",
      "Epoch 12/100\n",
      "5600/5600 [==============================] - 6s 984us/step - loss: 0.4879 - accuracy: 0.7834 - val_loss: 0.5065 - val_accuracy: 0.7700\n",
      "trn_score 0.7214443844176069 val_score 0.6942979070530839\n",
      "Epoch 13/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.4905 - accuracy: 0.7823 - val_loss: 0.5067 - val_accuracy: 0.7714\n",
      "trn_score 0.7458064314322718 val_score 0.7121223767112906\n",
      "Epoch 14/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.4827 - accuracy: 0.7891 - val_loss: 0.4879 - val_accuracy: 0.7729\n",
      "trn_score 0.7138435143483851 val_score 0.6896726136192509\n",
      "Epoch 15/100\n",
      "5600/5600 [==============================] - 6s 991us/step - loss: 0.4825 - accuracy: 0.7861 - val_loss: 0.4936 - val_accuracy: 0.7686\n",
      "trn_score 0.7163502539132246 val_score 0.6844494653463106\n",
      "Epoch 16/100\n",
      "5600/5600 [==============================] - 6s 989us/step - loss: 0.4780 - accuracy: 0.7821 - val_loss: 0.4779 - val_accuracy: 0.7764\n",
      "trn_score 0.7079957339590855 val_score 0.6840728307587701\n",
      "Epoch 17/100\n",
      "5600/5600 [==============================] - 5s 979us/step - loss: 0.4721 - accuracy: 0.7866 - val_loss: 0.4839 - val_accuracy: 0.7736\n",
      "trn_score 0.7423343499509776 val_score 0.7037876295736157\n",
      "Epoch 18/100\n",
      "5600/5600 [==============================] - 5s 977us/step - loss: 0.4716 - accuracy: 0.7830 - val_loss: 0.5030 - val_accuracy: 0.7700\n",
      "trn_score 0.7319496631323212 val_score 0.6909852355823273\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00018: early stopping\n",
      "\n",
      "F1_0_val is:0.7426900584795322, F1_1_val is:0.8351515151515153, F1_2_val is:0.5622317596566524, total score is : 0.7133577777625666\n",
      "\n",
      "fold: 2\n",
      "Train on 5600 samples, validate on 1400 samples\n",
      "Epoch 1/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.6874 - accuracy: 0.7068 - val_loss: 0.5670 - val_accuracy: 0.7600\n",
      "trn_score 0.6809967616968775 val_score 0.6932190789949403\n",
      "Epoch 2/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.6037 - accuracy: 0.7429 - val_loss: 0.5432 - val_accuracy: 0.7721\n",
      "trn_score 0.5610138363688765 val_score 0.5919911066785497\n",
      "Epoch 3/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.5775 - accuracy: 0.7502 - val_loss: 0.5410 - val_accuracy: 0.7836\n",
      "trn_score 0.6283095185465367 val_score 0.6505448049590518\n",
      "Epoch 4/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.5577 - accuracy: 0.7536 - val_loss: 0.5113 - val_accuracy: 0.7843\n",
      "trn_score 0.6465491769216521 val_score 0.6621790835515299\n",
      "Epoch 5/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.5419 - accuracy: 0.7639 - val_loss: 0.5108 - val_accuracy: 0.7821\n",
      "trn_score 0.681546104921051 val_score 0.6899902528610321\n",
      "Epoch 6/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.5431 - accuracy: 0.7602 - val_loss: 0.4987 - val_accuracy: 0.7864\n",
      "trn_score 0.7105987025904215 val_score 0.7174828223705779\n",
      "Epoch 7/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.5267 - accuracy: 0.7663 - val_loss: 0.5035 - val_accuracy: 0.7843\n",
      "trn_score 0.7168594317494593 val_score 0.7101111626220642\n",
      "Epoch 8/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.5204 - accuracy: 0.7704 - val_loss: 0.4925 - val_accuracy: 0.7836\n",
      "trn_score 0.7200146825270267 val_score 0.7291649410010942\n",
      "Epoch 9/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.5213 - accuracy: 0.7677 - val_loss: 0.4889 - val_accuracy: 0.7857\n",
      "trn_score 0.7224594223424236 val_score 0.7236123119669841\n",
      "Epoch 10/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.5047 - accuracy: 0.7745 - val_loss: 0.4852 - val_accuracy: 0.7857\n",
      "trn_score 0.6588197629105952 val_score 0.6650854365701485\n",
      "Epoch 11/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.5038 - accuracy: 0.7675 - val_loss: 0.4762 - val_accuracy: 0.7957\n",
      "trn_score 0.7231349895093385 val_score 0.7339579866071387\n",
      "Epoch 12/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.5060 - accuracy: 0.7754 - val_loss: 0.4809 - val_accuracy: 0.7814\n",
      "trn_score 0.7229802138170692 val_score 0.7147403488390923\n",
      "Epoch 13/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.4937 - accuracy: 0.7766 - val_loss: 0.4781 - val_accuracy: 0.7857\n",
      "trn_score 0.7057353520219974 val_score 0.7019063209578998\n",
      "Epoch 14/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.4598 - accuracy: 0.7907 - val_loss: 0.4697 - val_accuracy: 0.8007\n",
      "trn_score 0.7390193054707401 val_score 0.7362787840453985\n",
      "Epoch 27/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.4529 - accuracy: 0.7950 - val_loss: 0.4629 - val_accuracy: 0.7936\n",
      "trn_score 0.7274968801716492 val_score 0.7122921423656962\n",
      "Epoch 28/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.4502 - accuracy: 0.7932 - val_loss: 0.4771 - val_accuracy: 0.7921\n",
      "trn_score 0.7594545850116671 val_score 0.732775302689138\n",
      "Epoch 29/100\n",
      "5600/5600 [==============================] - 6s 1ms/step - loss: 0.4576 - accuracy: 0.7904 - val_loss: 0.4574 - val_accuracy: 0.7879\n",
      "trn_score 0.7430057690924565 val_score 0.7149701665412108\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00029: early stopping\n",
      "\n",
      "F1_0_val is:0.7563527653213752, F1_1_val is:0.8614845119812975, F1_2_val is:0.6, total score is : 0.7392790924342242\n",
      "\n",
      "fold: 3\n",
      "Train on 5601 samples, validate on 1399 samples\n",
      "Epoch 1/100\n",
      "5601/5601 [==============================] - 6s 1ms/step - loss: 0.7261 - accuracy: 0.6995 - val_loss: 0.5950 - val_accuracy: 0.7298\n",
      "trn_score 0.5123183311393745 val_score 0.4981163529548618\n",
      "Epoch 2/100\n",
      "5601/5601 [==============================] - 6s 995us/step - loss: 0.5999 - accuracy: 0.7434 - val_loss: 0.5496 - val_accuracy: 0.7641\n",
      "trn_score 0.6952805213325429 val_score 0.7085365025665631\n",
      "Epoch 3/100\n",
      "5601/5601 [==============================] - 6s 996us/step - loss: 0.5655 - accuracy: 0.7522 - val_loss: 0.5209 - val_accuracy: 0.7870\n",
      "trn_score 0.6883642179295228 val_score 0.7173866367869094\n",
      "Epoch 4/100\n",
      "5601/5601 [==============================] - 6s 994us/step - loss: 0.5377 - accuracy: 0.7574 - val_loss: 0.5123 - val_accuracy: 0.7727\n",
      "trn_score 0.6324801019502984 val_score 0.6433326416289251\n",
      "Epoch 5/100\n",
      "5601/5601 [==============================] - 6s 1ms/step - loss: 0.5349 - accuracy: 0.7647 - val_loss: 0.5000 - val_accuracy: 0.7848\n",
      "trn_score 0.6997171266322102 val_score 0.70544974210474\n",
      "Epoch 6/100\n",
      "5601/5601 [==============================] - 6s 998us/step - loss: 0.5164 - accuracy: 0.7699 - val_loss: 0.4879 - val_accuracy: 0.7941\n",
      "trn_score 0.7337426325599972 val_score 0.7396515245375644\n",
      "Epoch 7/100\n",
      "5601/5601 [==============================] - 6s 1ms/step - loss: 0.5083 - accuracy: 0.7736 - val_loss: 0.4890 - val_accuracy: 0.7848\n",
      "trn_score 0.6895444385170157 val_score 0.6860613072332141\n",
      "Epoch 8/100\n",
      "5601/5601 [==============================] - 6s 996us/step - loss: 0.4992 - accuracy: 0.7693 - val_loss: 0.4856 - val_accuracy: 0.7956\n",
      "trn_score 0.7129226487545464 val_score 0.7342053789044165\n",
      "Epoch 9/100\n",
      "5601/5601 [==============================] - 6s 990us/step - loss: 0.4977 - accuracy: 0.7702 - val_loss: 0.4814 - val_accuracy: 0.7970\n",
      "trn_score 0.7162283529265245 val_score 0.7242335484044635\n",
      "Epoch 10/100\n",
      "5601/5601 [==============================] - 6s 986us/step - loss: 0.4816 - accuracy: 0.7808 - val_loss: 0.4970 - val_accuracy: 0.7941\n",
      "trn_score 0.7207696898359227 val_score 0.7281188416051748\n",
      "Epoch 11/100\n",
      "5601/5601 [==============================] - 6s 990us/step - loss: 0.4827 - accuracy: 0.7741 - val_loss: 0.4851 - val_accuracy: 0.7863\n",
      "trn_score 0.7236130858265041 val_score 0.7157131235336195\n",
      "Epoch 12/100\n",
      "5601/5601 [==============================] - 6s 991us/step - loss: 0.4830 - accuracy: 0.7763 - val_loss: 0.4809 - val_accuracy: 0.7963\n",
      "trn_score 0.7280061711433831 val_score 0.7278602048462867\n",
      "Epoch 13/100\n",
      "5601/5601 [==============================] - 6s 996us/step - loss: 0.4716 - accuracy: 0.7945 - val_loss: 0.4778 - val_accuracy: 0.7820\n",
      "trn_score 0.7398537208506556 val_score 0.7323485008877442\n",
      "Epoch 14/100\n",
      "5601/5601 [==============================] - 6s 1ms/step - loss: 0.4783 - accuracy: 0.7859 - val_loss: 0.4641 - val_accuracy: 0.7884\n",
      "trn_score 0.7379657983890824 val_score 0.7226331476943723\n",
      "Epoch 15/100\n",
      "5601/5601 [==============================] - 6s 1ms/step - loss: 0.4708 - accuracy: 0.7883 - val_loss: 0.4716 - val_accuracy: 0.7713\n",
      "trn_score 0.7521054858522289 val_score 0.7198702618699926\n",
      "Epoch 16/100\n",
      "5601/5601 [==============================] - 6s 1ms/step - loss: 0.4652 - accuracy: 0.7849 - val_loss: 0.4667 - val_accuracy: 0.7870\n",
      "trn_score 0.6971641965486531 val_score 0.6869863222972284\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00016: early stopping\n",
      "\n",
      "F1_0_val is:0.7463126843657816, F1_1_val is:0.8579846788450207, F1_2_val is:0.6146572104018913, total score is : 0.7396515245375644\n",
      "\n",
      "fold: 4\n",
      "Train on 5601 samples, validate on 1399 samples\n",
      "Epoch 1/100\n",
      "5601/5601 [==============================] - 6s 1ms/step - loss: 0.6975 - accuracy: 0.7129 - val_loss: 0.6021 - val_accuracy: 0.7505\n",
      "trn_score 0.5524879045168184 val_score 0.5534647896054244\n",
      "Epoch 2/100\n",
      "5601/5601 [==============================] - 6s 1ms/step - loss: 0.6058 - accuracy: 0.7500 - val_loss: 0.5711 - val_accuracy: 0.7448\n",
      "trn_score 0.5540112563832281 val_score 0.5453079580573345\n",
      "Epoch 3/100\n",
      "5601/5601 [==============================] - 6s 1ms/step - loss: 0.5650 - accuracy: 0.7615 - val_loss: 0.5450 - val_accuracy: 0.7720\n",
      "trn_score 0.6347551765168938 val_score 0.6290680304508033\n",
      "Epoch 4/100\n",
      "5601/5601 [==============================] - 6s 992us/step - loss: 0.5583 - accuracy: 0.7568 - val_loss: 0.5326 - val_accuracy: 0.7798\n",
      "trn_score 0.7000759345556696 val_score 0.7042328923156146\n",
      "Epoch 5/100\n",
      "5601/5601 [==============================] - 6s 985us/step - loss: 0.5383 - accuracy: 0.7629 - val_loss: 0.5260 - val_accuracy: 0.7756\n",
      "trn_score 0.6646118735859602 val_score 0.6670173019206075\n",
      "Epoch 6/100\n",
      "5601/5601 [==============================] - 6s 987us/step - loss: 0.5293 - accuracy: 0.7650 - val_loss: 0.5075 - val_accuracy: 0.7877\n",
      "trn_score 0.6785212347925761 val_score 0.680392983775878\n",
      "Epoch 7/100\n",
      "5601/5601 [==============================] - 6s 994us/step - loss: 0.5198 - accuracy: 0.7656 - val_loss: 0.4932 - val_accuracy: 0.7927\n",
      "trn_score 0.7042550362575742 val_score 0.7131084666145758\n",
      "Epoch 8/100\n",
      "5601/5601 [==============================] - 6s 991us/step - loss: 0.5191 - accuracy: 0.7711 - val_loss: 0.5000 - val_accuracy: 0.7906\n",
      "trn_score 0.690665357555515 val_score 0.694290968308804\n",
      "Epoch 9/100\n",
      "5601/5601 [==============================] - 6s 994us/step - loss: 0.5089 - accuracy: 0.7686 - val_loss: 0.5255 - val_accuracy: 0.7856\n",
      "trn_score 0.6825403434987837 val_score 0.683686956653727\n",
      "Epoch 10/100\n",
      "5601/5601 [==============================] - 6s 991us/step - loss: 0.5061 - accuracy: 0.7734 - val_loss: 0.4856 - val_accuracy: 0.7920\n",
      "trn_score 0.7097609147920988 val_score 0.7080498127108297\n",
      "Epoch 11/100\n",
      "5601/5601 [==============================] - 6s 1000us/step - loss: 0.5007 - accuracy: 0.7775 - val_loss: 0.4832 - val_accuracy: 0.7877\n",
      "trn_score 0.6778886074213663 val_score 0.6792416264998288\n",
      "Epoch 12/100\n",
      "5601/5601 [==============================] - 6s 997us/step - loss: 0.4907 - accuracy: 0.7791 - val_loss: 0.4714 - val_accuracy: 0.8006\n",
      "trn_score 0.719499618505528 val_score 0.727155612154036\n",
      "Epoch 13/100\n",
      "5601/5601 [==============================] - 6s 994us/step - loss: 0.4881 - accuracy: 0.7775 - val_loss: 0.4662 - val_accuracy: 0.8020\n",
      "trn_score 0.7225886566251996 val_score 0.7203927682799011\n",
      "Epoch 14/100\n",
      "5601/5601 [==============================] - 6s 991us/step - loss: 0.4820 - accuracy: 0.7852 - val_loss: 0.4583 - val_accuracy: 0.8027\n",
      "trn_score 0.7260580122226444 val_score 0.728375130892922\n",
      "Epoch 15/100\n",
      "5601/5601 [==============================] - 6s 993us/step - loss: 0.4816 - accuracy: 0.7833 - val_loss: 0.4635 - val_accuracy: 0.8006\n",
      "trn_score 0.7239836766638175 val_score 0.7314838068049697\n",
      "Epoch 16/100\n",
      "5601/5601 [==============================] - 6s 993us/step - loss: 0.4770 - accuracy: 0.7815 - val_loss: 0.4475 - val_accuracy: 0.8049\n",
      "trn_score 0.7410954303320421 val_score 0.7445138200634517\n",
      "Epoch 17/100\n",
      "5601/5601 [==============================] - 6s 994us/step - loss: 0.4704 - accuracy: 0.7815 - val_loss: 0.4672 - val_accuracy: 0.8027\n",
      "trn_score 0.7433673690176539 val_score 0.7446501978216937\n",
      "Epoch 18/100\n",
      "5601/5601 [==============================] - 6s 1ms/step - loss: 0.4669 - accuracy: 0.7872 - val_loss: 0.4586 - val_accuracy: 0.8063\n",
      "trn_score 0.734545310721022 val_score 0.7418467118790776\n",
      "Epoch 19/100\n",
      "5601/5601 [==============================] - 6s 998us/step - loss: 0.4635 - accuracy: 0.7888 - val_loss: 0.4556 - val_accuracy: 0.7913\n",
      "trn_score 0.687788119950682 val_score 0.6723050308586865\n",
      "Epoch 20/100\n",
      "5601/5601 [==============================] - 6s 1ms/step - loss: 0.4606 - accuracy: 0.7911 - val_loss: 0.4456 - val_accuracy: 0.8106\n",
      "trn_score 0.753345784886512 val_score 0.7507270031859387\n",
      "Epoch 21/100\n",
      "5601/5601 [==============================] - 6s 995us/step - loss: 0.4588 - accuracy: 0.7936 - val_loss: 0.4801 - val_accuracy: 0.7934\n",
      "trn_score 0.7076702012378125 val_score 0.6990047598131911\n",
      "Epoch 22/100\n",
      "5601/5601 [==============================] - 6s 994us/step - loss: 0.4603 - accuracy: 0.7893 - val_loss: 0.4584 - val_accuracy: 0.8049\n",
      "trn_score 0.7148549452238733 val_score 0.7169749702409693\n",
      "Epoch 23/100\n",
      "5601/5601 [==============================] - 6s 996us/step - loss: 0.4561 - accuracy: 0.7913 - val_loss: 0.4478 - val_accuracy: 0.8077\n",
      "trn_score 0.738172129663004 val_score 0.7261428595681471\n",
      "Epoch 24/100\n",
      "5601/5601 [==============================] - 6s 1ms/step - loss: 0.4569 - accuracy: 0.7897 - val_loss: 0.4563 - val_accuracy: 0.7913\n",
      "trn_score 0.6999928888694847 val_score 0.6746878974023017\n",
      "Epoch 25/100\n",
      "5601/5601 [==============================] - 6s 996us/step - loss: 0.4507 - accuracy: 0.7961 - val_loss: 0.4707 - val_accuracy: 0.7813\n",
      "trn_score 0.7485234189762185 val_score 0.734826672328059\n",
      "Epoch 26/100\n",
      "5601/5601 [==============================] - 6s 992us/step - loss: 0.4575 - accuracy: 0.7904 - val_loss: 0.4546 - val_accuracy: 0.8134\n",
      "trn_score 0.7369225861818945 val_score 0.7374690328825669\n",
      "Epoch 27/100\n",
      "5601/5601 [==============================] - 6s 986us/step - loss: 0.4495 - accuracy: 0.7950 - val_loss: 0.4396 - val_accuracy: 0.8170\n",
      "trn_score 0.7499992682800237 val_score 0.7553364132873884\n",
      "Epoch 28/100\n",
      "5601/5601 [==============================] - 6s 990us/step - loss: 0.4517 - accuracy: 0.7900 - val_loss: 0.4542 - val_accuracy: 0.7906\n",
      "trn_score 0.7031612754603765 val_score 0.6824003432264597\n",
      "Epoch 29/100\n",
      "5601/5601 [==============================] - 6s 990us/step - loss: 0.4452 - accuracy: 0.7963 - val_loss: 0.4522 - val_accuracy: 0.8034\n",
      "trn_score 0.7225563935704885 val_score 0.7122561433787569\n",
      "Epoch 30/100\n",
      "5601/5601 [==============================] - 6s 995us/step - loss: 0.4454 - accuracy: 0.7979 - val_loss: 0.4549 - val_accuracy: 0.8091\n",
      "trn_score 0.7635353549721712 val_score 0.7461065188956502\n",
      "Epoch 31/100\n",
      "5601/5601 [==============================] - 6s 992us/step - loss: 0.4455 - accuracy: 0.7974 - val_loss: 0.4503 - val_accuracy: 0.7977\n",
      "trn_score 0.6993515275916243 val_score 0.6901062652760354\n",
      "Epoch 32/100\n",
      "5601/5601 [==============================] - 6s 991us/step - loss: 0.4419 - accuracy: 0.7977 - val_loss: 0.4516 - val_accuracy: 0.8027\n",
      "trn_score 0.7334604502622679 val_score 0.7174195557376882\n",
      "Epoch 33/100\n",
      "5601/5601 [==============================] - 6s 995us/step - loss: 0.4443 - accuracy: 0.8004 - val_loss: 0.4446 - val_accuracy: 0.8070\n",
      "trn_score 0.754353246536151 val_score 0.7386625655676284\n",
      "Epoch 34/100\n",
      "5601/5601 [==============================] - 6s 998us/step - loss: 0.4426 - accuracy: 0.7984 - val_loss: 0.4566 - val_accuracy: 0.8063\n",
      "trn_score 0.7471523891352194 val_score 0.7287430721607443\n",
      "Epoch 35/100\n",
      "5601/5601 [==============================] - 6s 996us/step - loss: 0.4352 - accuracy: 0.8031 - val_loss: 0.4365 - val_accuracy: 0.8056\n",
      "trn_score 0.74932487027856 val_score 0.7341198055706291\n",
      "Epoch 36/100\n",
      "5601/5601 [==============================] - 6s 997us/step - loss: 0.4308 - accuracy: 0.8009 - val_loss: 0.4402 - val_accuracy: 0.8049\n",
      "trn_score 0.7377406443473751 val_score 0.7193172764709201\n",
      "Epoch 37/100\n",
      "5601/5601 [==============================] - 6s 1ms/step - loss: 0.4365 - accuracy: 0.7979 - val_loss: 0.4461 - val_accuracy: 0.7963\n",
      "trn_score 0.737450980411599 val_score 0.703972360025551\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00037: early stopping\n",
      "\n",
      "F1_0_val is:0.7701674277016742, F1_1_val is:0.8819804260218769, F1_2_val is:0.6138613861386139, total score is : 0.7553364132873884\n",
      "\n",
      "\n",
      "F1_0_val is:0.7450281982784209, F1_1_val is:0.8577469752143779, F1_2_val is:0.5873465533522191, total score is : 0.730040575615006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.730040575615006"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras \n",
    "\n",
    "b_size = 2\n",
    "max_epochs = 100\n",
    "oof_pred = np.zeros((len(train), ))\n",
    "models = []\n",
    "for fold, (trn_idx, val_idx) in enumerate(kf.split(train[important], train.type)):\n",
    "    print('fold:', fold)\n",
    "    X_train, y_train = train[important].loc[trn_idx], target[trn_idx]\n",
    "    X_val, y_val = train[important].loc[val_idx], target[val_idx]\n",
    "    \n",
    "    model = NN_model()\n",
    "    simple_adam = keras.optimizers.Adam()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=simple_adam, metrics=['accuracy'])\n",
    "    es = EarlyStopping(monitor='val_score', patience=10, verbose=1, mode='max', restore_best_weights=True,)\n",
    "    es.set_model(model)\n",
    "    metric = Metric(model, [es], [(X_train, y_train), (X_val, y_val)])\n",
    "    model.fit(X_train, y_train, batch_size=b_size, epochs=max_epochs, \n",
    "              validation_data = [X_val, y_val],\n",
    "              callbacks=[metric], shuffle=True, verbose=1)\n",
    "    y_pred3 = model.predict(X_val)\n",
    "    y_pred = np.zeros((len(y_pred3), ))\n",
    "    models.append(model)\n",
    "    for i in range(len(y_pred3)):\n",
    "        y_pred[i] = list(y_pred3[i]).index(max(y_pred3[i]))\n",
    "        \n",
    "    oof_pred[val_idx] = y_pred\n",
    "    F1_0_val, F1_1_val, F1_2_val = F1_score(train.type.loc[val_idx], y_pred)\n",
    "    score_ = (F1_0_val + F1_1_val + F1_2_val)/3\n",
    "    print()\n",
    "    print('F1_0_val is:{}, F1_1_val is:{}, F1_2_val is:{}, total score is : {}'.format(F1_0_val, F1_1_val, F1_2_val, score_))\n",
    "    print()\n",
    "\n",
    "F1_0, F1_1, F1_2 = F1_score(train.type, oof_pred)\n",
    "score_ = (F1_0 + F1_1 + F1_2)/3\n",
    "print()\n",
    "print('F1_0_val is:{}, F1_1_val is:{}, F1_2_val is:{}, total score is : {}'.format(F1_0, F1_1, F1_2, score_))\n",
    "f1_score(train.type, oof_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = feature_engineer(test, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_std</th>\n",
       "      <th>x_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>x_mean</th>\n",
       "      <th>y_std</th>\n",
       "      <th>y_min</th>\n",
       "      <th>y_max</th>\n",
       "      <th>y_mean</th>\n",
       "      <th>speed_sin_std</th>\n",
       "      <th>speed_sin_max</th>\n",
       "      <th>speed_sin_mean</th>\n",
       "      <th>speed_cos_std</th>\n",
       "      <th>speed_cos_max</th>\n",
       "      <th>speed_cos_mean</th>\n",
       "      <th>speed_std</th>\n",
       "      <th>speed_max</th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>ori_std</th>\n",
       "      <th>ori_max</th>\n",
       "      <th>ori_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.262833</td>\n",
       "      <td>3.069990</td>\n",
       "      <td>3.035617</td>\n",
       "      <td>3.101512</td>\n",
       "      <td>-0.406656</td>\n",
       "      <td>2.393115</td>\n",
       "      <td>2.453454</td>\n",
       "      <td>2.432599</td>\n",
       "      <td>0.363191</td>\n",
       "      <td>0.469540</td>\n",
       "      <td>0.520874</td>\n",
       "      <td>0.538807</td>\n",
       "      <td>0.455983</td>\n",
       "      <td>-0.638705</td>\n",
       "      <td>1.042360</td>\n",
       "      <td>0.021187</td>\n",
       "      <td>-0.144552</td>\n",
       "      <td>0.507427</td>\n",
       "      <td>0.254471</td>\n",
       "      <td>0.379963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.404578</td>\n",
       "      <td>-0.098783</td>\n",
       "      <td>-0.211853</td>\n",
       "      <td>-0.138093</td>\n",
       "      <td>0.066743</td>\n",
       "      <td>-0.237080</td>\n",
       "      <td>-0.217537</td>\n",
       "      <td>-0.234868</td>\n",
       "      <td>0.466428</td>\n",
       "      <td>0.518821</td>\n",
       "      <td>-0.292704</td>\n",
       "      <td>1.105678</td>\n",
       "      <td>0.822715</td>\n",
       "      <td>0.113178</td>\n",
       "      <td>0.467624</td>\n",
       "      <td>0.021187</td>\n",
       "      <td>0.860456</td>\n",
       "      <td>0.077351</td>\n",
       "      <td>0.180373</td>\n",
       "      <td>0.624419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.944927</td>\n",
       "      <td>1.199837</td>\n",
       "      <td>1.632259</td>\n",
       "      <td>1.530079</td>\n",
       "      <td>1.641883</td>\n",
       "      <td>0.528292</td>\n",
       "      <td>0.983135</td>\n",
       "      <td>0.785946</td>\n",
       "      <td>0.645973</td>\n",
       "      <td>0.212303</td>\n",
       "      <td>1.821421</td>\n",
       "      <td>0.553906</td>\n",
       "      <td>0.507174</td>\n",
       "      <td>2.347646</td>\n",
       "      <td>0.719707</td>\n",
       "      <td>0.021187</td>\n",
       "      <td>0.797401</td>\n",
       "      <td>0.425439</td>\n",
       "      <td>0.235947</td>\n",
       "      <td>0.820567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.129142</td>\n",
       "      <td>-0.343044</td>\n",
       "      <td>-0.397233</td>\n",
       "      <td>-0.436262</td>\n",
       "      <td>-0.430396</td>\n",
       "      <td>-0.244431</td>\n",
       "      <td>-0.349826</td>\n",
       "      <td>-0.272895</td>\n",
       "      <td>0.446298</td>\n",
       "      <td>0.575161</td>\n",
       "      <td>-0.041552</td>\n",
       "      <td>-0.108925</td>\n",
       "      <td>0.110184</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.836987</td>\n",
       "      <td>0.021187</td>\n",
       "      <td>-0.515798</td>\n",
       "      <td>0.661055</td>\n",
       "      <td>0.254471</td>\n",
       "      <td>0.078360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.072288</td>\n",
       "      <td>0.393188</td>\n",
       "      <td>0.360064</td>\n",
       "      <td>0.311796</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.376797</td>\n",
       "      <td>0.388380</td>\n",
       "      <td>0.466091</td>\n",
       "      <td>0.296491</td>\n",
       "      <td>0.661817</td>\n",
       "      <td>0.571083</td>\n",
       "      <td>0.306650</td>\n",
       "      <td>0.284893</td>\n",
       "      <td>-0.275893</td>\n",
       "      <td>0.868187</td>\n",
       "      <td>0.021187</td>\n",
       "      <td>-0.274008</td>\n",
       "      <td>0.544657</td>\n",
       "      <td>0.161849</td>\n",
       "      <td>0.110225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1.272909</td>\n",
       "      <td>0.448762</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.434242</td>\n",
       "      <td>-0.564160</td>\n",
       "      <td>0.631898</td>\n",
       "      <td>0.476017</td>\n",
       "      <td>0.536370</td>\n",
       "      <td>1.310504</td>\n",
       "      <td>-0.028098</td>\n",
       "      <td>-2.264725</td>\n",
       "      <td>-0.229295</td>\n",
       "      <td>0.822326</td>\n",
       "      <td>-0.305646</td>\n",
       "      <td>1.530288</td>\n",
       "      <td>0.021187</td>\n",
       "      <td>0.095520</td>\n",
       "      <td>0.388622</td>\n",
       "      <td>0.180373</td>\n",
       "      <td>0.821723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-0.396299</td>\n",
       "      <td>0.525873</td>\n",
       "      <td>0.411600</td>\n",
       "      <td>0.493597</td>\n",
       "      <td>0.624527</td>\n",
       "      <td>0.386501</td>\n",
       "      <td>0.529850</td>\n",
       "      <td>0.411957</td>\n",
       "      <td>0.184931</td>\n",
       "      <td>0.668171</td>\n",
       "      <td>-0.182833</td>\n",
       "      <td>1.381210</td>\n",
       "      <td>0.783881</td>\n",
       "      <td>0.274104</td>\n",
       "      <td>0.353567</td>\n",
       "      <td>0.021187</td>\n",
       "      <td>0.969127</td>\n",
       "      <td>0.187911</td>\n",
       "      <td>0.235947</td>\n",
       "      <td>0.889243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-0.736703</td>\n",
       "      <td>0.556438</td>\n",
       "      <td>0.306443</td>\n",
       "      <td>0.446030</td>\n",
       "      <td>-0.770590</td>\n",
       "      <td>0.858814</td>\n",
       "      <td>0.642283</td>\n",
       "      <td>0.758270</td>\n",
       "      <td>-1.602782</td>\n",
       "      <td>-1.452558</td>\n",
       "      <td>0.012218</td>\n",
       "      <td>-1.608907</td>\n",
       "      <td>-1.637190</td>\n",
       "      <td>0.040152</td>\n",
       "      <td>-1.760166</td>\n",
       "      <td>-1.513177</td>\n",
       "      <td>-1.272015</td>\n",
       "      <td>-2.916314</td>\n",
       "      <td>-0.060445</td>\n",
       "      <td>-2.286806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-0.145311</td>\n",
       "      <td>-0.130097</td>\n",
       "      <td>-0.178028</td>\n",
       "      <td>-0.150768</td>\n",
       "      <td>1.458013</td>\n",
       "      <td>-0.457088</td>\n",
       "      <td>-0.218293</td>\n",
       "      <td>-0.273590</td>\n",
       "      <td>-0.063972</td>\n",
       "      <td>0.281910</td>\n",
       "      <td>-0.285366</td>\n",
       "      <td>0.560433</td>\n",
       "      <td>-0.433942</td>\n",
       "      <td>-1.623616</td>\n",
       "      <td>0.572493</td>\n",
       "      <td>0.021187</td>\n",
       "      <td>0.098524</td>\n",
       "      <td>0.254146</td>\n",
       "      <td>0.217422</td>\n",
       "      <td>0.245763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-0.735580</td>\n",
       "      <td>0.150931</td>\n",
       "      <td>-0.103776</td>\n",
       "      <td>0.031596</td>\n",
       "      <td>-0.768013</td>\n",
       "      <td>0.156667</td>\n",
       "      <td>-0.062688</td>\n",
       "      <td>0.035580</td>\n",
       "      <td>-1.584258</td>\n",
       "      <td>-1.427678</td>\n",
       "      <td>0.006610</td>\n",
       "      <td>-1.601653</td>\n",
       "      <td>-1.583989</td>\n",
       "      <td>-0.005587</td>\n",
       "      <td>-1.742756</td>\n",
       "      <td>-1.479993</td>\n",
       "      <td>-1.287878</td>\n",
       "      <td>-2.835202</td>\n",
       "      <td>-0.190117</td>\n",
       "      <td>-2.284700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x_std     x_min     x_max    x_mean     y_std     y_min     y_max  \\\n",
       "0    -0.262833  3.069990  3.035617  3.101512 -0.406656  2.393115  2.453454   \n",
       "1    -0.404578 -0.098783 -0.211853 -0.138093  0.066743 -0.237080 -0.217537   \n",
       "2     0.944927  1.199837  1.632259  1.530079  1.641883  0.528292  0.983135   \n",
       "3    -0.129142 -0.343044 -0.397233 -0.436262 -0.430396 -0.244431 -0.349826   \n",
       "4    -0.072288  0.393188  0.360064  0.311796  0.001638  0.376797  0.388380   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  1.272909  0.448762  0.813073  0.434242 -0.564160  0.631898  0.476017   \n",
       "1996 -0.396299  0.525873  0.411600  0.493597  0.624527  0.386501  0.529850   \n",
       "1997 -0.736703  0.556438  0.306443  0.446030 -0.770590  0.858814  0.642283   \n",
       "1998 -0.145311 -0.130097 -0.178028 -0.150768  1.458013 -0.457088 -0.218293   \n",
       "1999 -0.735580  0.150931 -0.103776  0.031596 -0.768013  0.156667 -0.062688   \n",
       "\n",
       "        y_mean  speed_sin_std  speed_sin_max  speed_sin_mean  speed_cos_std  \\\n",
       "0     2.432599       0.363191       0.469540        0.520874       0.538807   \n",
       "1    -0.234868       0.466428       0.518821       -0.292704       1.105678   \n",
       "2     0.785946       0.645973       0.212303        1.821421       0.553906   \n",
       "3    -0.272895       0.446298       0.575161       -0.041552      -0.108925   \n",
       "4     0.466091       0.296491       0.661817        0.571083       0.306650   \n",
       "...        ...            ...            ...             ...            ...   \n",
       "1995  0.536370       1.310504      -0.028098       -2.264725      -0.229295   \n",
       "1996  0.411957       0.184931       0.668171       -0.182833       1.381210   \n",
       "1997  0.758270      -1.602782      -1.452558        0.012218      -1.608907   \n",
       "1998 -0.273590      -0.063972       0.281910       -0.285366       0.560433   \n",
       "1999  0.035580      -1.584258      -1.427678        0.006610      -1.601653   \n",
       "\n",
       "      speed_cos_max  speed_cos_mean  speed_std  speed_max  speed_mean  \\\n",
       "0          0.455983       -0.638705   1.042360   0.021187   -0.144552   \n",
       "1          0.822715        0.113178   0.467624   0.021187    0.860456   \n",
       "2          0.507174        2.347646   0.719707   0.021187    0.797401   \n",
       "3          0.110184        0.000014   0.836987   0.021187   -0.515798   \n",
       "4          0.284893       -0.275893   0.868187   0.021187   -0.274008   \n",
       "...             ...             ...        ...        ...         ...   \n",
       "1995       0.822326       -0.305646   1.530288   0.021187    0.095520   \n",
       "1996       0.783881        0.274104   0.353567   0.021187    0.969127   \n",
       "1997      -1.637190        0.040152  -1.760166  -1.513177   -1.272015   \n",
       "1998      -0.433942       -1.623616   0.572493   0.021187    0.098524   \n",
       "1999      -1.583989       -0.005587  -1.742756  -1.479993   -1.287878   \n",
       "\n",
       "       ori_std   ori_max  ori_mean  \n",
       "0     0.507427  0.254471  0.379963  \n",
       "1     0.077351  0.180373  0.624419  \n",
       "2     0.425439  0.235947  0.820567  \n",
       "3     0.661055  0.254471  0.078360  \n",
       "4     0.544657  0.161849  0.110225  \n",
       "...        ...       ...       ...  \n",
       "1995  0.388622  0.180373  0.821723  \n",
       "1996  0.187911  0.235947  0.889243  \n",
       "1997 -2.916314 -0.060445 -2.286806  \n",
       "1998  0.254146  0.217422  0.245763  \n",
       "1999 -2.835202 -0.190117 -2.284700  \n",
       "\n",
       "[2000 rows x 20 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[important] = scaler.fit_transform(test[important])\n",
    "test[important]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "for model in models:\n",
    "    y_preds.append(model.predict(test[important]))\n",
    "y = np.mean(y_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = np.zeros([len(y), 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [2.],\n",
       "        [1.],\n",
       "        [2.]]), 2000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ = np.zeros([len(y), 1])\n",
    "\n",
    "for i in range(len(y)):\n",
    "    y_[i] = list(y[i]).index(max(y[i]))\n",
    "y_, len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f4c8955d390>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_ = pd.DataFrame(y_)\n",
    "y_.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000</td>\n",
       "      <td>围网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7001</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7002</td>\n",
       "      <td>围网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7003</td>\n",
       "      <td>刺网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7004</td>\n",
       "      <td>围网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>8995</td>\n",
       "      <td>围网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>8996</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>8997</td>\n",
       "      <td>刺网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>8998</td>\n",
       "      <td>拖网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>8999</td>\n",
       "      <td>刺网</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id type\n",
       "0     7000   围网\n",
       "1     7001   拖网\n",
       "2     7002   围网\n",
       "3     7003   刺网\n",
       "4     7004   围网\n",
       "...    ...  ...\n",
       "1995  8995   围网\n",
       "1996  8996   拖网\n",
       "1997  8997   刺网\n",
       "1998  8998   拖网\n",
       "1999  8999   刺网\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = test.id\n",
    "submission['type'] = test.id\n",
    "submission['type'] = y_\n",
    "submission.type = submission.type.map(type_dict_inverse)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
